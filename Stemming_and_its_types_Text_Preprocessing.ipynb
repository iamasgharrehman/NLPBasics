{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Stemming**\n",
        "it is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as lemma. Stemming is Import in natural langauge understanding (**NLU**) and natural langauge processing."
      ],
      "metadata": {
        "id": "K3gTEwWbd9Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## classification problem\n",
        "## weather the comment on a product is postive or negative review\n",
        "## Reviews ----> Postive or negative\n",
        "## the words eating,eat, eaten have derived from the same root word eat, similarly\n",
        "## going, gone and goes also belongs to the same family of roots word--> go\n",
        "words= ['writing', 'writes', 'written', 'going', 'goes', 'gone', 'going', 'programming', 'programs', 'fairly', 'surprisingly', 'supported', 'supporting', 'repeated', 'repeatedly', 'Abnormous']"
      ],
      "metadata": {
        "id": "aFru3k09e963"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PosterStemmer**"
      ],
      "metadata": {
        "id": "CLm0f-7Nf2VY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer= PorterStemmer()\n",
        "for word in words:\n",
        "  print(word, '-->', stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALPyD6mLf1k1",
        "outputId": "aafbb0d7-8f19-489c-94c6-4b78b1f6039d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "writing --> write\n",
            "writes --> write\n",
            "written --> written\n",
            "going --> go\n",
            "goes --> goe\n",
            "gone --> gone\n",
            "going --> go\n",
            "programming --> program\n",
            "programs --> program\n",
            "fairly --> fairli\n",
            "surprisingly --> surprisingli\n",
            "supported --> support\n",
            "supporting --> support\n",
            "repeated --> repeat\n",
            "repeatedly --> repeatedli\n",
            "Abnormous --> abnorm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result**\n",
        "it can be seen that PosterStammer works well with most of the words to give the root words for different forms of words but it is not perfroming well on some of the words like\n",
        "1. Goes -> Goe\n",
        "2. Gone -> Gone\n",
        "3. fairly -> fairli\n",
        "4. surprisingly -> surpringli\n",
        "5. repeatedly -> repeatedli\n",
        "it seems that it is trying to remove s from the end of the words which correct for most of the words but not for all also it is converting if y is present at the end to i which in not correct\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "-mfJ8UV-sr6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RgexpStemmer**\n",
        "NLTK has RegexpStemmer class with the help of which we can easily implement  stemming. In this techinque we give our custom regex to perfrom stemming. let's check this techinque."
      ],
      "metadata": {
        "id": "OqnyarlVekGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "stemmer= RegexpStemmer('ing$|s$|e$|able$|es$', min=4)\n",
        "for word in words:\n",
        "  print(word, '-->', stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbTjNviAuM8G",
        "outputId": "013a7528-b67a-43f8-e072-fef8d0cd1d2e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "writing --> writ\n",
            "writes --> writ\n",
            "written --> written\n",
            "going --> go\n",
            "goes --> go\n",
            "gone --> gon\n",
            "going --> go\n",
            "programming --> programm\n",
            "programs --> program\n",
            "fairly --> fairly\n",
            "surprisingly --> surprisingly\n",
            "supported --> supported\n",
            "supporting --> support\n",
            "repeated --> repeated\n",
            "repeatedly --> repeatedly\n",
            "Abnormous --> Abnormou\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result**\n",
        "As we can see that it is working well on the words with the words ending at ly. we can give our custom regex to further import the performence of this techique. But this techique also has limmitations and can be used for some of the use cases like text classification problems"
      ],
      "metadata": {
        "id": "KIuiS6wVudPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bd-KRK-WucbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Snowball Stemmer**\n",
        "\n",
        "It is a steeming algorithm which is also knwon as he Porter2 stemming algorithm as it is a better version of Porter Stemmer since some issue of proter were fixed in this stemming techique"
      ],
      "metadata": {
        "id": "gIxM3dhEvBun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "stemmer= SnowballStemmer('english')\n",
        "for word in words:\n",
        "  print(word, '-->', stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxaXkwOlvA9v",
        "outputId": "c02a9d96-58b0-427f-b7de-6f3a1f332992"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "writing --> write\n",
            "writes --> write\n",
            "written --> written\n",
            "going --> go\n",
            "goes --> goe\n",
            "gone --> gone\n",
            "going --> go\n",
            "programming --> program\n",
            "programs --> program\n",
            "fairly --> fair\n",
            "surprisingly --> surpris\n",
            "supported --> support\n",
            "supporting --> support\n",
            "repeated --> repeat\n",
            "repeatedly --> repeat\n",
            "Abnormous --> abnorm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result**\n",
        "clealy it is performing well as compared to other two stemmers but still it wrongly stemming goes to goe and it is not stemming written which should be stemmed to its root word write and also it is wrong is stemming surprisingly to surpis\n"
      ],
      "metadata": {
        "id": "nuWlaSUfwHQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusion**\n",
        "We can draw the conclusion from above experience that although stemmer can be used in text classification but it is not a good idea to use to it for making chatbots and generative AI applications where we need our model to generate the text by itself here is the limmitation of stemming and we have to move towards other techique called as **Lemmitization**"
      ],
      "metadata": {
        "id": "9Z1V6T1MwsF7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rtD14vQexZ4P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}